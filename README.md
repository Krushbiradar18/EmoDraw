
# ğŸ–Œï¸ EmoDraw: Real-Time Air Drawing & Shape Recognition with AI<br>

EmoDraw is a fun and experimental AI project that lets you draw shapes in the air using your finger â€” tracked via webcam â€” and predicts what you've drawn using a trained Convolutional Neural Network (CNN). ğŸ¯<br>

https://github.com/krushbiradar18/EmoDraw<br>

---

## ğŸš€ Features<br>

- âœ‹ Finger tracking using **MediaPipe + OpenCV**<br>
- ğŸ¨ Draw in the air by moving your finger â€” real-time canvas overlay<br>
- ğŸ§  Predicts the shape using a trained **CNN model**<br>
- ğŸ’¾ Save your drawings and collect custom datasets<br>
- ğŸ§½ Eraser mode to fix parts of the sketch<br>
- ğŸ” Class prediction with confidence score<br>
- ğŸ“· Works in real-time with webcam<br>

---

## ğŸ§  Built With<br>

- `Python`<br>
- `OpenCV`<br>
- `MediaPipe`<br>
- `TensorFlow / Keras`<br>
- `NumPy`<br>

---

## ğŸ“ Folder Structure<br>

EmoDraw/
â”œâ”€â”€ hand_draw.py              # Real-time drawing & prediction script
â”œâ”€â”€ train_emodraw_cnn.py      # CNN training script
â”œâ”€â”€ dataset/                  # Folder where labeled drawings are stored
â”œâ”€â”€ emodraw_cnn_model.h5      # Trained CNN model
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## âš™ï¸ Setup Instructions<br>

1. **Clone the repo**<br>
   `git clone https://github.com/krushbiradar18/EmoDraw.git`<br>
   `cd EmoDraw`<br>

2. **Set up a virtual environment**<br>
   `python3 -m venv venv`<br>
   `source venv/bin/activate` (or `venv\Scripts\activate` on Windows)<br>

3. **Install dependencies**<br>
   `pip install -r requirements.txt`<br>

4. **Run the air drawing app**<br>
   `python hand_draw.py`<br>

---

## ğŸ–¼ï¸ How It Works<br>

- The webcam captures your hand.<br>
- MediaPipe tracks your **index fingertip**.<br>
- You can toggle between:<br>
  - `D` â†’ Start/stop drawing<br>
  - `E` â†’ Eraser mode<br>
  - `S` â†’ Save canvas<br>
  - `P` â†’ Predict the shape<br>
  - `C` â†’ Clear the canvas<br>
  - `Q` â†’ Quit<br>

---

## ğŸ¤– Training Your Own Model<br>

You can collect your own dataset using the drawing tool:<br>

`python hand_draw.py`<br>

1. Toggle draw mode (`D`)<br>
2. Draw a shape in the air<br>
3. Press `S` to save it (label is chosen at startup)<br>
4. Repeat for other shapes<br>
5. Once done, train using:<br>
   `python train_emodraw_cnn.py`<br>

---

## ğŸ“Œ Example Classes<br>

```python
class_names = ['star', 'sun', 'tree', 'smiley_face', 'flower', 'heart']

You can change or expand these by modifying your dataset folder structure.

â¸»

ğŸ™‹â€â™€ï¸ Author

Krushnali Biradar
GitHub | LinkedIn

â¸»

ğŸ’¡ Future Ideas
	â€¢	Add gesture-based mode switching (no keyboard needed)
	â€¢	Integrate sound or emoji overlay for detected shapes
	â€¢	Deploy as a Streamlit or Gradio app

â¸»

ğŸª„ License

This project is open-source and free to use under the MIT License.

